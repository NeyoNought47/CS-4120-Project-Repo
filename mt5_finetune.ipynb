{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e90f9fd690484b26971a307ef10ba49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72f05903c49f407cbc8d58edc6244355",
              "IPY_MODEL_cb95429284ff43e1ab48f47042a4d4ee",
              "IPY_MODEL_10ff244a8dd54fbf9d1d59b722fc7cf0"
            ],
            "layout": "IPY_MODEL_ba4f44bdf4a24d0792387c2af7ff9e3a"
          }
        },
        "72f05903c49f407cbc8d58edc6244355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717d3188bbee4104b6663f92785e781c",
            "placeholder": "​",
            "style": "IPY_MODEL_fb3d92812ed149069ba0632342486713",
            "value": "Map: 100%"
          }
        },
        "cb95429284ff43e1ab48f47042a4d4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9987c0e1e721401994746660df3fe62f",
            "max": 1216,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_738aba0d563f4b6094754448d648d8e3",
            "value": 1216
          }
        },
        "10ff244a8dd54fbf9d1d59b722fc7cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320e36177eff4a4e958e7c62be0fd3ae",
            "placeholder": "​",
            "style": "IPY_MODEL_8b31f9230f8e40e3b3b8ed33d984245d",
            "value": " 1216/1216 [00:01&lt;00:00, 998.48 examples/s]"
          }
        },
        "ba4f44bdf4a24d0792387c2af7ff9e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717d3188bbee4104b6663f92785e781c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb3d92812ed149069ba0632342486713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9987c0e1e721401994746660df3fe62f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738aba0d563f4b6094754448d648d8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "320e36177eff4a4e958e7c62be0fd3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b31f9230f8e40e3b3b8ed33d984245d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3c117fc7",
        "outputId": "d570cd26-60b8-4fe2-ffc1-6fa05563e7e2"
      },
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File structure\n",
        "'''mt5_HuggingFace/\n",
        "├── data/\n",
        "│   ├── gnome_en_es_pairs_ar.csv\n",
        "│   └── gnome_en_es_pairs_do.csv\n",
        "└── mt5/\n",
        "    ├── mt5_finetune.ipynb\n",
        "    └── my_saved_mt5_model/'''"
      ],
      "metadata": {
        "id": "Vlsfcq-9DHqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "686450b8"
      },
      "source": [
        "# Instructions to Run This Notebook (Using Pre-trained Model)\n",
        "\n",
        "These instructions will guide you through running the notebook to use the *already saved* pre-trained MT5 model for translation, skipping the training steps to save 15+ minutes.\n",
        "\n",
        "### 1. Data and Notebook Access\n",
        "*   **Share the Saved Model:** Ensure the `mt5` folder containing the saved model and notebook, this is also the default folder to save the model.\n",
        "*   **Original Data (Optional):** The original data files (`gnome_en_es_pairs_ar.csv`, etc.) are only needed if you intend to run trainning model. __And you also need to modify the data path__.\n",
        "\n",
        "### 2. Everything Runs in Google Colab\n",
        "\n",
        "### 3. Mount Google Drive\n",
        "\n",
        "### 4. Verify Model Path\n",
        "*   Ensure that the `model_save_path` variable points to the intended location of saved model in Google Drive. Based on __my__ steps, this is `/content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model`.\n",
        "\n",
        "### 5. Install Required Libraries\n",
        "\n",
        "### 6. Set Up GPU Runtime\n",
        "\n",
        "### 7. Run Necessary Cells in Order\n",
        "*   Since you're using a pre-trained model, you will skip the entire training process.\n",
        "*   **Minimum cells to run:**\n",
        "    *   **Mount Drive**\n",
        "    *   **Load Model & Tokenizer:** This cell should look something like this in my path:\n",
        "        ```python\n",
        "        model_path = \"/content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model\"\n",
        "        tokenizer = T5TokenizerFast.from_pretrained(model_path)\n",
        "        model = MT5ForConditionalGeneration.from_pretrained(model_path)\n",
        "        print(f\"Model and tokenizer loaded from: {model_path}\")\n",
        "        ```\n",
        "    *   **Define `translate_mt5` function**\n",
        "    *   **Define decoding configs**\n",
        "    *   **Run translation examples**\n",
        "\n",
        "\n",
        "### 8. View Output\n",
        "*   The translation outputs will be printed directly below the relevant cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca56fd20"
      },
      "source": [
        "## Overall Notebook Logic and Process Flow\n",
        "\n",
        "Fine-tuning a pre-trained mT5 model for English to Spanish machine translation, specifically for dialectal variations found in Gnome project data\n",
        "\n",
        "1.  **Data Loading and Preparation**:\n",
        "    *   **Source Data**: It loads English-Spanish phrase pairs from CSV files (e.g., `gnome_en_es_pairs_ar.csv`) into Hugging Face `Dataset` objects.\n",
        "    *   **Dataset Addition**: Multiple dialectal datasets can be loaded and concatenated into a single `data_files`.\n",
        "    *   **Train/Validation Split**\n",
        "\n",
        "2.  **Model and Tokenizer Initialization**:\n",
        "    *   **Base Model**: A pre-trained `google/mt5-small` model and its corresponding `T5TokenizerFast` are loaded from Hugging Face Hub. mT5 (Massive Text-to-Text Transfer Transformer) is a multilingual encoder-decoder model suitable for translation tasks.\n",
        "    *   **Task Prefix**: A `task_prefix` (\"translate English to Spanish: \") is defined.\n",
        "    *   **Tokenization**: A `preprocess_batch` function is defined to tokenize both the English source and Spanish target sentences. __It also adds the task prefix to the English input.__\n",
        "\n",
        "3.  **Model Training**:\n",
        "    *   **Data Collator**: `DataCollatorForSeq2Seq`\n",
        "    *   **Training Arguments**: `Seq2SeqTrainingArguments`\n",
        "    *   **Trainer Setup**: A `Seq2SeqTrainer`\n",
        "    *   **Training Execution**: `trainer.train()`\n",
        "\n",
        "4.  **Model saved to a specified directory on Google Drive**\n",
        "\n",
        "5.  **Inference and Decoding Strategies**:\n",
        "    *   **`translate_mt5` Function**: performs translations. It takes an English text, the model, and tokenizer, along with various decoding parameters.\n",
        "        *   **Greedy Decoding**: Selects the most probable token at each step.\n",
        "        *   **Beam Search**: Keeps track of multiple probable sequences to find a globally better translation.\n",
        "        *   **Length Penalty**: Adjusts the likelihood of longer or shorter sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5150c4b"
      },
      "source": [
        "云端硬盘挂载成功后，请提供您要加载的数据文件的完整路径（例如，`/content/drive/My Drive/your_folder/your_file.csv`），我将帮助您将其加载到 pandas DataFrame 中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7b30d024",
        "outputId": "69d7cbf5-6eeb-4698-e2ea-c3aa52b5f05a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/CS4120/data/gnome_en_es_pairs_ar.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  en  \\\n",
              "0  _Keyboard Accessibility Preferences _Help _Abo...   \n",
              "1  XKB Extension is not enabled Unknown error Err...   \n",
              "2  To avoid losing your work: • plug your laptop ...   \n",
              "3  To avoid losing your work: • suspend your lapt...   \n",
              "4  Your battery is running low No battery present...   \n",
              "\n",
              "                                                  es  \n",
              "0  Preferencias de accesibilidad del _teclado Ay_...  \n",
              "1  Serrador <serrador\\@cvs\\.gnome\\.org> Jorge Gon...  \n",
              "2  La extensión XKB no está activada Error descon...  \n",
              "3  Para evitar perder su trabajo: • enchufe su po...  \n",
              "4  Para evitar perder su trabajo: • suspenda su p...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cb0de10-4ab9-4532-a6f8-8b2ad726cc66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_Keyboard Accessibility Preferences _Help _Abo...</td>\n",
              "      <td>Preferencias de accesibilidad del _teclado Ay_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XKB Extension is not enabled Unknown error Err...</td>\n",
              "      <td>Serrador &lt;serrador\\@cvs\\.gnome\\.org&gt; Jorge Gon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To avoid losing your work: • plug your laptop ...</td>\n",
              "      <td>La extensión XKB no está activada Error descon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To avoid losing your work: • suspend your lapt...</td>\n",
              "      <td>Para evitar perder su trabajo: • enchufe su po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Your battery is running low No battery present...</td>\n",
              "      <td>Para evitar perder su trabajo: • suspenda su p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cb0de10-4ab9-4532-a6f8-8b2ad726cc66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cb0de10-4ab9-4532-a6f8-8b2ad726cc66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cb0de10-4ab9-4532-a6f8-8b2ad726cc66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-553c53f5-e519-4294-a98f-cc89f81124d4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-553c53f5-e519-4294-a98f-cc89f81124d4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-553c53f5-e519-4294-a98f-cc89f81124d4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"en\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"XKB Extension is not enabled Unknown error Error: %s Displays current state of keyboard accessibility features Battstat Factory Battery Charge Monitor Monitor a laptop's remaining power _Preferences System is running on AC power System is running on battery power Battery charged (%d%%) Unknown time (%d%%) remaining Unknown time (%d%%) until charged %d %s %d %s (%d%%) remaining %d %s %d %s until charged (%d%%) Battery Monitor Your battery is now fully recharged Battery Notice You have %d%% of your total battery capacity remaining.\",\n          \"Your battery is running low No battery present Battery status unknown N/A There was an error displaying help: %s This utility shows the status of your laptop battery.\",\n          \"To avoid losing your work: \\u2022 plug your laptop into external power, or \\u2022 save open documents and shut your laptop down.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"es\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Serrador <serrador\\\\@cvs\\\\.gnome\\\\.org> Jorge Gonz\\u00e1lez Gonz\\u00e1lez <jorge\\\\.gonzalez\\\\.gonzalez\\\\@hispalinux\\\\.es> Ha ocurrido un error lanzando el visor de ayuda: %s Ha ocurrido un error al lanzar el di\\u00e1logo de preferencias del teclado: %s a Estado de AccessX Muestra el estado del teclado cuando se usan las caracter\\u00edsticas de accesibilidad.\",\n          \"Para evitar perder su trabajo: \\u2022 suspenda su port\\u00e1til para ahorrar energ\\u00eda, \\u2022 enchufe su port\\u00e1til a una fuente de alimentaci\\u00f3n externa, o \\u2022 guarde los documentos abiertos y apague el port\\u00e1til.\",\n          \"La extensi\\u00f3n XKB no est\\u00e1 activada Error desconocido Error: %s Muestra el estado actual de las caracter\\u00edsticas de accesibilidad del teclado F\\u00e1brica para \\u00abEstado de la bater\\u00eda\\u00bb Monitor de carga bater\\u00eda Monitoriza la carga restante de un port\\u00e1til _Preferencias El sistema est\\u00e1 funcionando con CA El sistema est\\u00e1 funcionando con bater\\u00edas Bater\\u00eda cargada al (%d%%) Tiempo desconocido, (%d%%) restante Tiempo desconocido, (%d%%) hasta su carga Le quedan %d %s %d %s (%d%%) %d %s %d %s para cargarse (%d%%) Monitor de la bater\\u00eda La bater\\u00eda est\\u00e1 recargada completamente Notificaci\\u00f3n de bater\\u00eda Le queda un %d%% de la capacidad total de su bater\\u00eda.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "# Example: Dominican (do) + Argentine (ar); add other languages\n",
        "data_files = {\n",
        "    \"do\": \"/content/drive/MyDrive/CS4120/data/gnome_en_es_pairs_do.csv\",\n",
        "    \"ar\": \"/content/drive/MyDrive/CS4120/data/gnome_en_es_pairs_ar.csv\",\n",
        "    # \"cl\": \"data/gnome_en_es_pairs_cl.csv\", ...\n",
        "}\n",
        "\n",
        "datasets_list = []\n",
        "\n",
        "# (x: English input, y:Spanish translation) to train conditional model P(y|x)\n",
        "# get the dialect file abbreviation and its file path\n",
        "for dialect, path in data_files.items():\n",
        "    ds = load_dataset(\n",
        "        \"csv\",\n",
        "        data_files={\"train\": path}, # dict format\n",
        "    )[\"train\"]\n",
        "    # then adds a new column named dialect to each dataset, tagging every entry with its origin\n",
        "    ds = ds.add_column(\"dialect\", [dialect] * len(ds))\n",
        "    datasets_list.append(ds)\n",
        "\n",
        "# combine all dialect together\n",
        "full_ds = concatenate_datasets(datasets_list)\n",
        "print(full_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aflXRp61tvOX",
        "outputId": "e26cd15d-c0af-459f-e7b9-c2e8fa5e92e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['en', 'es', 'dialect'],\n",
            "    num_rows: 12160\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# e.g., 90% train, 10% validation\n",
        "dataset = full_ds.train_test_split(test_size=0.1, seed=42)\n",
        "train_ds = dataset[\"train\"]\n",
        "val_ds   = dataset[\"test\"]\n",
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8mR0-Vbv7gz",
        "outputId": "147658cb-ef81-4306-fad8-34e1a41ecdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['en', 'es', 'dialect'],\n",
              "    num_rows: 10944\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MT5ForConditionalGeneration, T5TokenizerFast\n",
        "\n",
        "# translation is like a text-to-text problem\n",
        "# input: en_sentence\n",
        "# output: es_sentence\n",
        "# import multilingual translation model and the tool needed to prepare text\n",
        "# the trainning process is to maximize the log-likelihood of the target sequence tokens (cross-entropy).\n",
        "model_name = \"google/mt5-small\"\n",
        "\n",
        "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gkOl8xgw2bX",
        "outputId": "ae78af26-a431-4bac-ede0-05284ff9c94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# raw text -> token IDs for subword tokenization and SentencePiece\n",
        "# Rather than BoW or fixed-length vectors, the model sees a sequence of (subword) indices;\n",
        "# the transformer turns them into contextual embeddings via self-attention.\n",
        "\n",
        "max_source_length = 128\n",
        "max_target_length = 128\n",
        "task_prefix = \"translate English to Spanish: \"\n",
        "\n",
        "def preprocess_batch(batch):\n",
        "    # 1. Build the input (source) text\n",
        "    inputs = [task_prefix + s for s in batch[\"en\"]]\n",
        "    targets = batch[\"es\"]\n",
        "\n",
        "    # 2. Tokenize inputs\n",
        "    # to convert both English inputs and Spanish targets into numerical token IDs\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=max_source_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    # 3. Tokenize targets (labels)\n",
        "    # It sets the tokenized Spanish sentences as labels for the model to learn from\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            targets,\n",
        "            max_length=max_target_length,\n",
        "            truncation=True,\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# use batch and remove the original text col\n",
        "train_tokenized = train_ds.map(\n",
        "    preprocess_batch,\n",
        "    batched=True,\n",
        "    remove_columns=train_ds.column_names,\n",
        ")\n",
        "\n",
        "val_tokenized = val_ds.map(\n",
        "    preprocess_batch,\n",
        "    batched=True,\n",
        "    remove_columns=val_ds.column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "e90f9fd690484b26971a307ef10ba49b",
            "72f05903c49f407cbc8d58edc6244355",
            "cb95429284ff43e1ab48f47042a4d4ee",
            "10ff244a8dd54fbf9d1d59b722fc7cf0",
            "ba4f44bdf4a24d0792387c2af7ff9e3a",
            "717d3188bbee4104b6663f92785e781c",
            "fb3d92812ed149069ba0632342486713",
            "9987c0e1e721401994746660df3fe62f",
            "738aba0d563f4b6094754448d648d8e3",
            "320e36177eff4a4e958e7c62be0fd3ae",
            "8b31f9230f8e40e3b3b8ed33d984245d"
          ]
        },
        "id": "Kz--ewrzy_So",
        "outputId": "a214ab86-25e0-4299-d342-e5b1fe5565e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1216 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e90f9fd690484b26971a307ef10ba49b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4118: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "# use Seq2SeqTrainer for encoder-decoder models\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# Seq2SeqTrainingArguments defines all the hyperparameters and strategies for training.\n",
        "# These arguments control various aspects of the training loop.\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"mt5-gnome-en-es\",   # Directory where model checkpoints and logs will be saved.\n",
        "    per_device_train_batch_size=4,  # Batch size for training on each device (GPU/CPU).\n",
        "    per_device_eval_batch_size=4,   # Batch size for evaluation on each device.\n",
        "    learning_rate=3e-4,             # The initial learning rate for the optimizer.\n",
        "    num_train_epochs=3,             # Total number of training epochs to perform.\n",
        "    logging_steps=100,              # Number of update steps between two logs.\n",
        "    eval_strategy=\"epoch\",          # Evaluate the model at the end of each epoch.\n",
        "    save_strategy=\"epoch\",          # Save the model checkpoint at the end of each epoch.\n",
        "    predict_with_generate=True,     # Whether to use generate to calculate metrics (useful for sequence generation tasks).\n",
        "    fp16=False,                     # Whether to use mixed precision training (float16). Set to True for performance on compatible GPUs.\n",
        ")"
      ],
      "metadata": {
        "id": "AoCHR85Dzf7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply LR and neural LMs, and minimize cross-entropy\n",
        "# coder–decoder transformer that learns a conditional distribution P(Spanish token | English tokens)\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWefp0qh1id6",
        "outputId": "bc5a8088-3c73-47fa-95de-a3397388c45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1775927734.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API key will be required here\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "l0R2JF0b187x",
        "outputId": "2928138c-59df-4067-e3b8-74bda540cad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mczzzttttt1\u001b[0m (\u001b[33mczzzttttt1-northeastern-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251129_221548-z2s8coql</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/czzzttttt1-northeastern-university/huggingface/runs/z2s8coql' target=\"_blank\">solar-water-3</a></strong> to <a href='https://wandb.ai/czzzttttt1-northeastern-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/czzzttttt1-northeastern-university/huggingface' target=\"_blank\">https://wandb.ai/czzzttttt1-northeastern-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/czzzttttt1-northeastern-university/huggingface/runs/z2s8coql' target=\"_blank\">https://wandb.ai/czzzttttt1-northeastern-university/huggingface/runs/z2s8coql</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8208' max='8208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8208/8208 40:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.347500</td>\n",
              "      <td>0.189084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.209300</td>\n",
              "      <td>0.154085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.160800</td>\n",
              "      <td>0.137550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8208, training_loss=0.650479611278045, metrics={'train_runtime': 2423.2316, 'train_samples_per_second': 13.549, 'train_steps_per_second': 3.387, 'total_flos': 2609751501619200.0, 'train_loss': 0.650479611278045, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil # Import shutil for directory deletion\n",
        "\n",
        "# Define the Google Drive path where to save the model\n",
        "model_save_path = \"/content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model\"\n",
        "\n",
        "# Ensure the parent directory exists\n",
        "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "# Check if the directory already exists and delete it to ensure a clean save\n",
        "if os.path.exists(model_save_path):\n",
        "    print(f\"Deleting existing directory: '{model_save_path}' to ensure a clean save.\")\n",
        "    shutil.rmtree(model_save_path)\n",
        "\n",
        "# Recreate the directory after deletion\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "\n",
        "# Save the trained model and tokenizer to the specified path\n",
        "trainer.save_model(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to: {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gewVPJSL2Zkq",
        "outputId": "b2651d40-1d11-4484-ca8f-123675437340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting existing directory: '/content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model' to ensure a clean save.\n",
            "Model and tokenizer saved to: /content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start to run from the below if you DON'T want to retrain the model(otherwise, it may take at least 15 minutes).**"
      ],
      "metadata": {
        "id": "APNOfHzq1LCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If there's error to load the saved model, you may need to downgrade the colab.\n",
        "# This is for compatibility issue\n",
        "'''import transformers\n",
        "print(transformers.__version__)\n",
        "\n",
        "!pip install -q \"transformers==4.57.1\"'''"
      ],
      "metadata": {
        "id": "ZpT3EMcA3vy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec825cd2",
        "outputId": "2f0c593c-a2db-4b56-b312-f833c9a784f9"
      },
      "source": [
        "from transformers import MT5ForConditionalGeneration, T5TokenizerFast\n",
        "import os\n",
        "\n",
        "# Load the tokenizer and model from the saved directory\n",
        "model_path = \"/content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model\"\n",
        "\n",
        "# Diagnostic code to check model_path contents with error checking\n",
        "print(f\"Attempting to load model from: {model_path}\")\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Error: Model path '{model_path}' does not exist. Please ensure the model was saved correctly and Google Drive is mounted.\")\n",
        "elif not os.listdir(model_path):\n",
        "    print(f\"Error: Model path '{model_path}' is empty. Please ensure the model was saved completely.\")\n",
        "else:\n",
        "    print(f\"Contents of '{model_path}':\")\n",
        "    for item in os.listdir(model_path):\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "# Load model and tokenizer with error checking\n",
        "# You're expected to see \"Model and tokenizer loaded successfully from:...\"\n",
        "try:\n",
        "    tokenizer = T5TokenizerFast.from_pretrained(model_path)\n",
        "    model = MT5ForConditionalGeneration.from_pretrained(model_path)\n",
        "    print(f\"Model and tokenizer loaded successfully from: {model_path}\")\n",
        "except AttributeError as e:\n",
        "    print(f\"\\nAn AttributeError occurred during model/tokenizer loading: {e}\")\n",
        "    print(\"This often happens if the configuration files (e.g., config.json, tokenizer_config.json) are missing or corrupted in the saved directory.\")\n",
        "    print(\"Please ensure the model was saved completely and correctly to the specified path, and try re-running the save cell first.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred during model/tokenizer loading: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load model from: /content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model\n",
            "Contents of '/content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model':\n",
            "  - config.json\n",
            "  - generation_config.json\n",
            "  - model.safetensors\n",
            "  - special_tokens_map.json\n",
            "  - spiece.model\n",
            "  - training_args.bin\n",
            "  - tokenizer_config.json\n",
            "  - tokenizer.json\n",
            "Model and tokenizer loaded successfully from: /content/drive/MyDrive/CS4120/mt5/my_saved_mt5_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoding process to find y_hat = argmaxP(y|x)\n",
        "#\tSo use heuristics:\n",
        "#\tGreedy: at each step take the most probable next token.\n",
        "#\tBeam search: keep the top k partial sequences (beam size), expand each, keep top k again.\n",
        "#\tAdd length penalties to avoid over-favoring short sequences.\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def translate_mt5(\n",
        "    text_en, # The English text to be translated\n",
        "    model,   # The MT5 model used for translation\n",
        "    tokenizer, # The tokenizer corresponding to the MT5 model\n",
        "    num_beams=1, # Number of beams for beam search. 1 means greedy decoding.\n",
        "    do_sample=False, # Whether to use sampling; False for deterministic decoding (beam search/greedy)\n",
        "    max_length=128, # Maximum length of the generated target sequence\n",
        "    length_penalty=1, # Penalty for generating longer sequences\n",
        "    temperature=1, # Controls randomness in sampling. Lower values make output more deterministic.\n",
        "    top_p=None, # Top-p (nucleus) sampling parameter\n",
        "):\n",
        "    # Prepare the input text with the task prefix\n",
        "    input_text = task_prefix + text_en\n",
        "    # Tokenize the input text and move it to the appropriate device (CPU/GPU)\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\", # Return PyTorch tensors\n",
        "        truncation=True,     # Truncate sequences longer than max_source_length\n",
        "        max_length=max_source_length,\n",
        "    ).to(device)\n",
        "\n",
        "    # Define generation arguments\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": max_length,\n",
        "        \"num_beams\": num_beams,\n",
        "        \"length_penalty\": length_penalty,\n",
        "        \"do_sample\": do_sample,\n",
        "        \"temperature\": temperature,\n",
        "    }\n",
        "\n",
        "    # Add top_p to generation arguments if specified\n",
        "    if top_p is not None:\n",
        "        gen_kwargs[\"top_p\"] = top_p\n",
        "\n",
        "    # Generate the output sequence (translated text token IDs)\n",
        "    output_ids = model.generate(**inputs, **gen_kwargs)\n",
        "    # Decode the generated token IDs back into human-readable text, skipping special tokens\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "0ce3mNOI9y-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoding_configs = [\n",
        "    {\"name\": \"greedy\",        \"num_beams\": 1, \"do_sample\": False, \"length_penalty\": 1.0},\n",
        "    {\"name\": \"beam_4\",        \"num_beams\": 4, \"do_sample\": False, \"length_penalty\": 1.0},\n",
        "    {\"name\": \"beam_8\",        \"num_beams\": 8, \"do_sample\": False, \"length_penalty\": 1.0},\n",
        "    {\"name\": \"beam_4_lp_0.6\", \"num_beams\": 4, \"do_sample\": False, \"length_penalty\": 0.6},\n",
        "    {\"name\": \"beam_4_lp_1.4\", \"num_beams\": 4, \"do_sample\": False, \"length_penalty\": 1.4},\n",
        "    # Optional:\n",
        "    # {\"name\": \"top_p_0.9\", \"num_beams\": 1, \"do_sample\": True,  \"top_p\": 0.9, \"temperature\": 0.7},\n",
        "]"
      ],
      "metadata": {
        "id": "8WT_HD4aEMRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defind those variable again in here(if you want to use the existing saved model rather than retrainning the model)\n",
        "max_source_length = 128\n",
        "max_target_length = 128\n",
        "task_prefix = \"translate English to Spanish: \""
      ],
      "metadata": {
        "id": "Wogbi5hs0sjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some test sentences to be translated\n",
        "test_examples = [\n",
        "    \"Keyboard Accessibility Preferences\",\n",
        "    \"Shows the status of keyboard accessibility features\",\n",
        "    \"There was an error launching the help viewer.\",\n",
        "]\n",
        "\n",
        "# Apply the model and get the translation with customized parameters(beam_# ...)\n",
        "for text in test_examples:\n",
        "    print(f\"\\nSOURCE: {text}\")\n",
        "    for cfg in decoding_configs:\n",
        "        out = translate_mt5(\n",
        "            text_en=text,\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            num_beams=cfg.get(\"num_beams\", 1),\n",
        "            do_sample=cfg.get(\"do_sample\", False),\n",
        "            length_penalty=cfg.get(\"length_penalty\", 1.0),\n",
        "            temperature=cfg.get(\"temperature\", 1.0),\n",
        "            top_p=cfg.get(\"top_p\", None),\n",
        "        )\n",
        "        print(f\"[{cfg['name']}] {out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU_1i-2yFRQc",
        "outputId": "12f1c08c-e75d-40f5-c0e8-d4be9d210f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SOURCE: Keyboard Accessibility Preferences\n",
            "[greedy] Color de tipografía, componente azul El componente azul del color de frente.\n",
            "[beam_4] Mostrar notas adhesivas _Borrar todas Nota adhesiva Bloquear/Desbloquear la nota Cerrar nota Redimensionar la nota Propiedades de la nota adhesiva _Propiedades Seleccione una tipografía para la nota Seleccione una tipografía para la nota adhesiva Usar la tipografía predetermi_nada Seleccione un color para la nota Seleccione un color para la nota adhesiva _Color de la nota: Color de la _tipografía: Usar el co_lor predeterminado Especifique un t\n",
            "[beam_8] Mostrar notas adhesivas _Borrar todas Nota adhesiva Bloquear/Desbloquear la nota Cerrar nota Redimensionar la nota Propiedades de la nota adhesiva _Propiedades Seleccione una tipografía para la nota Seleccione una tipografía para la nota adhesiva Usar la tipografía predetermi_nada Seleccione un color para la nota Seleccione un color para la nota adhesiva _Color de la nota: Color de la _tipografía: Usar el co_lor predeterminado Especifique un t\n",
            "[beam_4_lp_0.6] Mostrar notas adhesivas _Borrar todas Nota adhesiva Bloquear/Desbloquear la nota Cerrar nota Redimensionar la nota Propiedades de la nota adhesiva _Propiedades Seleccione una tipografía para la nota Seleccione una tipografía para la nota adhesiva Usar la tipografía predetermi_nada Seleccione un color para la nota Seleccione un color para la nota adhesiva _Color de la nota: Color de la _tipografía: Usar el co_lor predeterminado Especifique un t\n",
            "[beam_4_lp_1.4] Mostrar notas adhesivas _Borrar todas Nota adhesiva Bloquear/Desbloquear la nota Cerrar nota Redimensionar la nota Propiedades de la nota adhesiva _Propiedades Seleccione una tipografía para la nota Seleccione una tipografía para la nota adhesiva Usar la tipografía predetermi_nada Seleccione un color para la nota Seleccione un color para la nota adhesiva _Color de la nota: Color de la _tipografía: Usar el co_lor predeterminado Especifique un t\n",
            "\n",
            "SOURCE: Shows the status of keyboard accessibility features\n",
            "[greedy] Color de tipografía, componente azul El componente azul del color de frente.\n",
            "[beam_4] Mostrar el marco Mostrar un marco alrededor de la miniaplicación.\n",
            "[beam_8] Preferencias de accesibilidad del _teclado Ay_uda _Acerca de Fábrica de la miniaplicación Estado de AccessX Fábrica de la miniaplicación de estado de accesibilidad del teclado Estado de accesibilidad del teclado Muestra el estado de las características de accesibilidad del teclado Muestra el estado de las características AccessX como los modificadores bloqueadosdocumenters Francisco Javier F.\n",
            "[beam_4_lp_0.6] Mostrar el marco Mostrar un marco alrededor de la miniaplicación.\n",
            "[beam_4_lp_1.4] Mostrar el marco Mostrar un marco alrededor de la miniaplicación.\n",
            "\n",
            "SOURCE: There was an error launching the help viewer.\n",
            "[greedy] También el valor en el cual se muestra la advertencia de batería baja.\n",
            "[beam_4] Color de predeterminado para la tipografía Color predeterminado para la tipografía de las notas adhesivas nuevas.\n",
            "[beam_8] Color de predeterminado para la tipografía Color predeterminado para la tipografía de las notas adhesivas nuevas.\n",
            "[beam_4_lp_0.6] También el valor en el cual se muestra la advertencia de batería baja.\n",
            "[beam_4_lp_1.4] Color de predeterminado para la tipografía Color predeterminado para la tipografía de las notas adhesivas nuevas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output explanation:\n",
        "\n",
        "1. Greedy: the model simply picks the word with the highest probability as the next word in the sequence. It can be suboptimal because a locally optimal choice at one step might lead to a globally bad translation later on.\n",
        "2. Beam: Instead of just picking the single best word at each step, beam search keeps track of the num_beams (e.g., 4 or 8) most probable partial translations. Therefore, __it's less likely to get stuck in local optima. Increasing num_beams usually leads to better quality, up to a point.__\n",
        "3. lp_#: This parameter is used with beam search to influence the length of the generated translation. Models sometimes have a bias towards generating shorter sequences. A higher number will encourage to generate longer sequences. However, __if the outputs are the same, it means the length penalties doesn't alter the most probable sequence for this model__."
      ],
      "metadata": {
        "id": "ixAGptd2WKkQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next action: for who does evaluation can plug these outputs into BLEU / METEOR / chrF / COMET:\n",
        "\n",
        "\t•\tBeam_8 for Source 2 may be the best.\n",
        "\t•\tOnly train/validation split exists now. For proper evaluation, a test may to be set.\n",
        "\t•\tOr “Short length penalty caused truncated translations, which lowered chrF but sometimes looked okay.”"
      ],
      "metadata": {
        "id": "HSLLTHLUMkiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End of code"
      ],
      "metadata": {
        "id": "b_L4EMn8MhuY"
      }
    }
  ]
}