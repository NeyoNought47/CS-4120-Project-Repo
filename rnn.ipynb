{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTnJaK4WTYx3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_path = r\"C:\\Users\\shang\\Desktop\\clean\"\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(os.listdir(data_path))\n",
        "    print(\"The file exists\")\n",
        "else:\n",
        "    print(f\"{data_path} does not exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZSzQqeNU3wF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "region_data = {}\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    sub_folders = sorted(os.listdir(data_path))\n",
        "\n",
        "    for folder_name in sub_folders:\n",
        "        folder_full_path = os.path.join(data_path, folder_name)\n",
        "\n",
        "        if os.path.isdir(folder_full_path) and folder_name.startswith('es-'):\n",
        "            path_en = os.path.join(folder_full_path, 'all.en')\n",
        "            path_es = os.path.join(folder_full_path, 'all.es')\n",
        "\n",
        "            if os.path.exists(path_en) and os.path.exists(path_es):\n",
        "                with open(path_en, 'r', encoding='utf-8') as f:\n",
        "                    lines_en = f.read().strip().split('\\n')\n",
        "                with open(path_es, 'r', encoding='utf-8') as f:\n",
        "                    lines_es = f.read().strip().split('\\n')\n",
        "\n",
        "                current_pairs = []\n",
        "                if len(lines_en) == len(lines_es):\n",
        "                    for en, es in zip(lines_en, lines_es):\n",
        "                        if en.strip() and es.strip():\n",
        "                            current_pairs.append([en.strip(), es.strip()])\n",
        "\n",
        "                    region_data[folder_name] = current_pairs\n",
        "\n",
        "\n",
        "print(\"regions:\", list(region_data.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKWsJP88YL4R"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "UNK_token = 2  \n",
        "MAX_LENGTH = 20\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\"} \n",
        "        self.n_words = 3\n",
        "        \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"([.!?¿¡,])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-ZáéíóúñÁÉÍÓÚÑ.!?¿¡,]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "           len(p[1].split(' ')) < MAX_LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY8AcbSfZ3RS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    indexes = []\n",
        "    for word in sentence.split(' '):\n",
        "        if word in lang.word2index:\n",
        "            indexes.append(lang.word2index[word])\n",
        "        else:\n",
        "            indexes.append(UNK_token) \n",
        "    return indexes\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair, input_lang, output_lang):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8IZE9UmajhO"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size) \n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        output = embedded\n",
        "\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqVuSPfPatU2"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "        self.rnn = nn.RNN(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IpbdsSyexIm"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(encoder, decoder, validation_pairs, input_lang, output_lang, criterion):\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct_tokens = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    with torch.no_grad(): \n",
        "        for pair in validation_pairs:\n",
        "            input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "            target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "\n",
        "            input_length = input_tensor.size(0)\n",
        "            target_length = target_tensor.size(0)\n",
        "\n",
        "            encoder_hidden = encoder.initHidden()\n",
        "            encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
        "\n",
        "            for ei in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "                encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "            decoder_hidden = encoder_hidden \n",
        "\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden, _ = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "                loss = criterion(decoder_output, target_tensor[di])\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                if topi.item() == target_tensor[di].item():\n",
        "                    total_correct_tokens += 1\n",
        "                \n",
        "                total_tokens += 1\n",
        "\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "\n",
        "                if decoder_input.item() == EOS_token:\n",
        "                    break\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    avg_loss = total_loss / total_tokens if total_tokens > 0 else 0\n",
        "    avg_acc = total_correct_tokens / total_tokens if total_tokens > 0 else 0\n",
        "    \n",
        "    return avg_loss, avg_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAIUuDKPhPGB"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def train_step(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "    correct_tokens = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            if topi.item() == target_tensor[di].item():\n",
        "                correct_tokens += 1\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di] \n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            if topi.item() == target_tensor[di].item():\n",
        "                correct_tokens += 1\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length, correct_tokens / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doo7gIzEe6pM"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch import optim\n",
        "\n",
        "def train_specific_region_and_return_data(region_name, n_epochs=5, learning_rate=0.001, save_dir=\"models\"):\n",
        "\n",
        "    if region_name not in region_data:\n",
        "        print(f\"Error: region {region_name} not found\")\n",
        "        return None\n",
        "    \n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    raw_pairs = region_data[region_name]\n",
        "\n",
        "    input_lang = Lang(\"eng\")\n",
        "    output_lang = Lang(\"spa\")\n",
        "\n",
        "    clean_pairs = []\n",
        "    for en, es in raw_pairs:\n",
        "        clean_en = normalizeString(en)\n",
        "        clean_es = normalizeString(es)\n",
        "        if len(clean_en.split()) < MAX_LENGTH and len(clean_es.split()) < MAX_LENGTH:\n",
        "            clean_pairs.append([clean_en, clean_es])\n",
        "            input_lang.addSentence(clean_en)\n",
        "            output_lang.addSentence(clean_es)\n",
        "\n",
        "    random.shuffle(clean_pairs)\n",
        "    val_split = int(len(clean_pairs) * 0.8)\n",
        "    \n",
        "    train_pairs = clean_pairs[:val_split]\n",
        "    test_pairs = clean_pairs[val_split:] \n",
        "\n",
        "    hidden_size = 256\n",
        "    encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "    decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    steps_per_epoch = 5000\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "        \n",
        "        with tqdm(total=steps_per_epoch, unit=\"step\", desc=f\"Epoch {epoch}\") as pbar:\n",
        "            for i in range(steps_per_epoch):\n",
        "                pair = random.choice(train_pairs)\n",
        "                input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "                target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "                \n",
        "                loss, acc = train_step(input_tensor, target_tensor, encoder, decoder, \n",
        "                                     encoder_optimizer, decoder_optimizer, criterion)\n",
        "                epoch_loss += loss\n",
        "                epoch_acc += acc\n",
        "                pbar.set_postfix({'loss': f'{epoch_loss/(i+1):.3f}', 'acc': f'{epoch_acc/(i+1):.3f}'})\n",
        "                pbar.update(1)\n",
        "            \n",
        "            val_loss, val_acc = validate_epoch(\n",
        "            encoder, decoder, test_pairs[:200], input_lang, output_lang, criterion\n",
        "        )\n",
        "        \n",
        "        print(f\"Epoch {epoch} | Train Loss: {epoch_loss/steps_per_epoch:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    print(f\"{region_name} training completed!\")\n",
        "\n",
        "    save_path = os.path.join(save_dir, f\"model_{region_name}.pt\")\n",
        "    \n",
        "    checkpoint = {\n",
        "        'encoder_state_dict': encoder.state_dict(),\n",
        "        'decoder_state_dict': decoder.state_dict(),\n",
        "        'input_lang': input_lang, \n",
        "        'output_lang': output_lang,\n",
        "        'hidden_size': hidden_size\n",
        "    }\n",
        "    \n",
        "    torch.save(checkpoint, save_path)\n",
        "    print(f\"Model saved to: {save_path}\")\n",
        "    \n",
        "    return encoder, decoder, input_lang, output_lang, test_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "def generate_translations(encoder, decoder, test_pairs, input_lang, output_lang):\n",
        "    sources = []\n",
        "    references = []\n",
        "    predictions = []\n",
        "    \n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for pair in tqdm(test_pairs):\n",
        "            src_text = pair[0]\n",
        "            ref_text = pair[1]\n",
        "            \n",
        "            input_tensor = tensorFromSentence(input_lang, src_text)\n",
        "            input_length = input_tensor.size(0)\n",
        "            \n",
        "            encoder_hidden = encoder.initHidden()\n",
        "            encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
        "\n",
        "            for ei in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "                encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            decoded_words = []\n",
        "            \n",
        "            for di in range(MAX_LENGTH):\n",
        "                decoder_output, decoder_hidden, _ = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                \n",
        "                if topi.item() == EOS_token:\n",
        "                    break\n",
        "                else:\n",
        "                    decoded_words.append(output_lang.index2word[topi.item()])\n",
        "                \n",
        "                decoder_input = topi.squeeze().detach()\n",
        "            \n",
        "            pred_text = ' '.join(decoded_words)\n",
        "            \n",
        "            sources.append(src_text)\n",
        "            references.append(ref_text)\n",
        "            predictions.append(pred_text)\n",
        "            \n",
        "    return sources, references, predictions\n",
        "\n",
        "import evaluate\n",
        "\n",
        "def compute_metrics(sources, references, predictions):\n",
        "    results = {}\n",
        "\n",
        "    metric_bleu = evaluate.load(\"sacrebleu\")\n",
        "    metric_chrf = evaluate.load(\"chrf\")\n",
        "    metric_meteor = evaluate.load(\"meteor\")\n",
        "    metric_comet  = evaluate.load(\"comet\") \n",
        "\n",
        "    formatted_refs = [[r] for r in references]\n",
        "    \n",
        "    bleu_res = metric_bleu.compute(predictions=predictions, references=formatted_refs)\n",
        "    results['BLEU'] = bleu_res['score']\n",
        "    print(f\"BLEU: {results['BLEU']:.2f}\")\n",
        "\n",
        "    chrf_res = metric_chrf.compute(predictions=predictions, references=formatted_refs)\n",
        "    results['chrF'] = chrf_res['score']\n",
        "    print(f\"chrF: {results['chrF']:.2f}\")\n",
        "\n",
        "\n",
        "    meteor_res = metric_meteor.compute(predictions=predictions, references=references)\n",
        "    results['METEOR'] = meteor_res['meteor']\n",
        "    print(f\"METEOR: {results['METEOR']:.4f}\")\n",
        "\n",
        "\n",
        "    comet_res = metric_comet.compute(predictions=predictions, references=references, sources=sources)\n",
        "    results['COMET'] = comet_res['mean_score']\n",
        "    print(f\"COMET: {results['COMET']:.4f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    indexes = []\n",
        "    for word in sentence.split(' '):\n",
        "        if word in lang.word2index:\n",
        "            indexes.append(lang.word2index[word])\n",
        "        else:\n",
        "\n",
        "            continue \n",
        "    return indexes\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_regions = [\n",
        "    'es-SV', 'es-PE', 'es-NI', 'es-DO', 'es-EC', \n",
        "    'es-PA', 'es-PR', 'es-UY', 'es-CO', 'es-CR', \n",
        "    'es-VE', 'es-AR', 'es-HN', 'es-CL'\n",
        "]\n",
        "\n",
        "final_results = {}\n",
        "\n",
        "for region in target_regions:\n",
        "    encoder, decoder, lang_in, lang_out, test_data = train_specific_region_and_return_data(\n",
        "        region, n_epochs=5, learning_rate=0.001\n",
        "    )\n",
        "\n",
        "    eval_subset = test_data[:200]\n",
        "    \n",
        "    srcs, refs, preds = generate_translations(encoder, decoder, eval_subset, lang_in, lang_out)\n",
        "    scores = compute_metrics(srcs, refs, preds)\n",
        "    \n",
        "    for metric, score in scores.items():\n",
        "        val = score if isinstance(score, (int, float)) else 0.0\n",
        "        print(f\"{metric:<10}: {val:.4f}\")\n",
        "    \n",
        "    final_results[region] = scores\n",
        "\n",
        "print(f\"{'Region':<10} {'BLEU':<10} {'COMET':<10}\")\n",
        "for region, scores in final_results.items():\n",
        "    bleu = scores.get('BLEU', 0)\n",
        "    comet = scores.get('COMET', 0)\n",
        "    print(f\"{region:<10} {bleu:.2f}       {comet:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "colab_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
